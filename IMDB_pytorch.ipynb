{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Копия блокнота \"HACKANONS COLAB 25GB RAM.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tumanov-a/imdb_sentiment_analys/blob/main/IMDB_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "reviews = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv.zip', compression='zip')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61TUgHVDkKjP",
        "outputId": "345d0f31-b687-4bbb-8edb-db9dfb8ecc11"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzMkQ7zskOfs",
        "outputId": "4fb28110-460b-49a3-aac3-e170082d44ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcS30UZEkPQM"
      },
      "source": [
        "def replace_(fragment):\r\n",
        "  fragment = re.sub('<br />', '', fragment)\r\n",
        "  return fragment"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbquzqlIkXSx"
      },
      "source": [
        "reviews['review'] = reviews['review'].apply(replace_)\r\n",
        "reviews['review'] = reviews['review'].apply(lambda x: x[:512])\r\n",
        "reviews['sentiment'] = reviews['sentiment'].map({'positive': 1, 'negative': 0})"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKGXLYLFkYjr"
      },
      "source": [
        "reviews['review'] = reviews['review'].apply(lambda x: '[CLS] ' + x + ' [SEP]')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNrsFZ1ikajK"
      },
      "source": [
        "x, y = reviews.review, reviews.sentiment\r\n",
        "\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPstAB9vkc_H",
        "outputId": "ded225f5-2f02-441c-f4f2-cda0b58099a0"
      },
      "source": [
        "!pip install pytorch_transformers"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.1.95)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.0.43)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.3.4)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.5 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (1.20.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.5->boto3->pytorch_transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZeyNJwEkdVA"
      },
      "source": [
        "from pytorch_transformers import BertTokenizer, BertConfig\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\r\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in x_train]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxVHrLM-kfNP"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "\r\n",
        "input_ids = pad_sequences(input_ids, \r\n",
        "                          dtype='long', \r\n",
        "                          padding='post', \r\n",
        "                          truncating='post')\r\n",
        "\r\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\r\n",
        "\r\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, y_train, random_state=42, test_size=0.1)\r\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.1)\r\n",
        "\r\n",
        "train_labels, validation_labels = np.array(train_labels), np.array(validation_labels)\r\n",
        "\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "validation_labels = torch.tensor(validation_labels)\r\n",
        "validation_masks = torch.tensor(validation_masks)\r\n",
        "\r\n",
        "train_data = torch.utils.data.TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_dataloader = torch.utils.data.DataLoader(\r\n",
        "    train_data,\r\n",
        "    batch_size=16,\r\n",
        "    sampler=torch.utils.data.RandomSampler(train_data)\r\n",
        ")\r\n",
        "\r\n",
        "validation_data = torch.utils.data.TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_dataloader = torch.utils.data.DataLoader(\r\n",
        "    validation_data,\r\n",
        "    batch_size=16,\r\n",
        "    sampler=torch.utils.data.SequentialSampler(validation_data)\r\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfWrSFmSko8K"
      },
      "source": [
        "from pytorch_transformers import AdamW, BertForSequenceClassification, BertModel"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKpdI7bdkwRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffda8a85-e832-48ae-c99a-740d2bbe5dbe"
      },
      "source": [
        "class myBertModel(torch.nn.Module):\r\n",
        "  def __init__(self, hidden_neurons):\r\n",
        "    super(myBertModel, self).__init__()\r\n",
        "    config = BertConfig.from_pretrained('bert-base-uncased', num_labels=2)\r\n",
        "    self.model = BertModel.from_pretrained('bert-base-uncased', config=config)\r\n",
        "    self.hidden_neurons = hidden_neurons\r\n",
        "    self.linear_1 = torch.nn.Linear(config.hidden_size, self.hidden_neurons)\r\n",
        "    self.linear_2 = torch.nn.Linear(self.hidden_neurons, int(self.hidden_neurons / 2))\r\n",
        "    self.classifier = torch.nn.Linear(int(self.hidden_neurons / 2), 2)\r\n",
        "    self.activation = torch.nn.Sigmoid()\r\n",
        "    self.dropout = torch.nn.Dropout(.3)\r\n",
        "\r\n",
        "  def forward(self, features, attention_mask):\r\n",
        "    bert_output = self.model(input_ids=features, attention_mask=attention_mask)\r\n",
        "    seq_output = bert_output[0]\r\n",
        "    pooled_output = seq_output.mean(axis=1)\r\n",
        "    pooled_output = self.dropout(pooled_output)\r\n",
        "    linear_output = self.linear_1(pooled_output)\r\n",
        "    linear_output_2 = self.linear_2(linear_output)\r\n",
        "    scores = self.classifier(linear_output_2)\r\n",
        "    scores = self.dropout(scores)\r\n",
        "    scores = self.activation(scores)\r\n",
        "    return scores\r\n",
        "\r\n",
        "my_model = myBertModel(384)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 433/433 [00:00<00:00, 212786.60B/s]\n",
            "100%|██████████| 440473133/440473133 [00:47<00:00, 9179734.67B/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTqpnpFWt03b"
      },
      "source": [
        "optimizer = AdamW(my_model.parameters(), lr=2e-5)\r\n",
        "loss = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSV6ynCdoDw4",
        "outputId": "8d602d78-53d3-47d8-cd23-1c4184f28daf"
      },
      "source": [
        "my_model.cuda()\r\n",
        "my_model.train()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "myBertModel(\n",
              "  (model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (linear_1): Linear(in_features=768, out_features=384, bias=True)\n",
              "  (linear_2): Linear(in_features=384, out_features=192, bias=True)\n",
              "  (classifier): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (activation): Sigmoid()\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1QC4ZuWnvn-"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-MDC0iTkzAg",
        "outputId": "91cedf89-922d-4759-8dc3-6d5dbb430e3c"
      },
      "source": [
        "loss_set = []\r\n",
        "my_model.train()\r\n",
        "\r\n",
        "for epoch in tqdm(range(2)):\r\n",
        "  for batch in train_dataloader:\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    b_input_ids, b_input_mask, b_labels = batch\r\n",
        "    optimizer.zero_grad()\r\n",
        "    pred_labels = my_model.forward(b_input_ids, b_input_mask)\r\n",
        "    my_loss = loss(pred_labels, b_labels)\r\n",
        "    loss_set.append(my_loss.item())\r\n",
        "    my_loss.backward()\r\n",
        "    optimizer.step()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "100%|██████████| 2/2 [28:23<00:00, 851.67s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "gbgi6GmiauCh",
        "outputId": "e234883b-352f-42ba-f70a-3ed3140a3761"
      },
      "source": [
        "plt.plot(loss_set)\r\n",
        "plt.title('Train loss')\r\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnRLiCgkmU7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf7b097-d687-473f-cb74-11e917c00a29"
      },
      "source": [
        "my_model.eval()\r\n",
        "\r\n",
        "test_preds, test_labels, test_probs = [], [], []\r\n",
        "\r\n",
        "for batch in tqdm(validation_dataloader):\r\n",
        "  batch = tuple(t.to(device) for t in batch)\r\n",
        "  b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    pred_labels = my_model.forward(b_input_ids, b_input_mask)\r\n",
        "\r\n",
        "  b_labels = b_labels.to('cpu').numpy()\r\n",
        "  pred_labels = pred_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "  test_probs.extend(pred_labels)\r\n",
        "  pred_labels = pred_labels.argmax(axis=1)\r\n",
        "  \r\n",
        "  test_labels.extend(b_labels)\r\n",
        "  test_preds.extend(pred_labels)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:29<00:00,  7.34it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxkaPI23odMF",
        "outputId": "6bb3631d-7575-48d1-8812-8669a3b59877"
      },
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, f1_score\r\n",
        "\r\n",
        "test_probs = [list(probs) for probs in test_probs]\r\n",
        "test_probs_f = np.array(test_probs)[:, 1]\r\n",
        "\r\n",
        "print(classification_report(test_labels, test_preds))\r\n",
        "print('roc_auc ', round(roc_auc_score(test_labels, test_probs_f), 2))\r\n",
        "print('f1 ', round(f1_score(test_labels, test_preds), 2))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.88      1758\n",
            "           1       0.88      0.87      0.88      1742\n",
            "\n",
            "    accuracy                           0.88      3500\n",
            "   macro avg       0.88      0.88      0.88      3500\n",
            "weighted avg       0.88      0.88      0.88      3500\n",
            "\n",
            "roc_auc  0.95\n",
            "f1  0.88\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}